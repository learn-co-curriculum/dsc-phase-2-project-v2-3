{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: Joel Omondi, Aaron Onserio, James Mbeti, Victoria Nabea, Nyokabi Waiganjo, Kennedy Juma\n",
    "* Student pace: full time\n",
    "* Scheduled project review date/time: 20/04/2023\n",
    "* Instructor name: Lucille Kaleha\n",
    "* Blog post URL: \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **VALUE ANALYSIS FOR HOUSE SALE PRICES IN KING COUNTY**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Business Overview**\n",
    "## _Will your home renovations pay off?_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ### **Introduction**\n",
    "\n",
    "* In this project, the task is to undertake research on property market in King County and to determine the major factors for the houses within the neighbourhoods for a real estate agency.\n",
    "\n",
    "* The objective of this project is to utilize multiple linear regression modeling to evaluate house sales data in King County Washington, USA. The aim is to gain insights and make predictions about the factors that affect house sales in the area as well as lucrative neighbourhoods to invest in while using statistical techniques to support relevant recommendations.\n",
    "\n",
    "* Remodeling certain areas of a property is an excellent way for homeowners to add increased functionality and beauty to a property at someone else's expense. By choosing the right project to enhance your living space, a significant portion of the expense can be passed on to future owners in the form of increased property values\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ### **Business Problem / Problem Statement**\n",
    "\n",
    "The real estate agency needs to provide advice to homeowners regarding how home renovations can potentially increase the estimated value of their properties and homes and by what amount. This information will assist the real estate agency in advising their clients about how to make informed decisions regarding home renovations, and in turn, assist homeowners in maximizing the return on their investment when selling their properties.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ### **Proposal**\n",
    "\n",
    "* We will focus on analysing house sales in a northwestern county for a possible stakeholder, a real estate agency helping homeowners buy and/or sell homes. Specifically, we will address the business problem of providing homeowners advice on how home renovations can increase the estimated value of their homes and by what amount.\n",
    "\n",
    "* \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Understanding**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This project uses the King County House Sales dataset, which can be found in \"kc_house_data.csv\"\n",
    "\n",
    "* One of the challenges that may arise in this project is the incomplete or ambiguous description of the column names in the dataset. However, with thorough research or good judgment, we can understand the data and make informed decisions on which variables to use in our analysis. \n",
    "\n",
    "* Another challenge is ensuring that the linear regression model we develop adds value to our analysis, rather than simply fulfilling the project's requirement. \n",
    "\n",
    "* The dataset includes information on house sales in King County such as the prices, the design, the size in square footages, the location etc. Others can be found at ['Property Schema'](https://github.com/learn-co-curriculum/dsc-phase-2-project-v2-3/blob/main/data/column_names.md)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Objectives*\n",
    "\n",
    "* To determine the increase in prices of property due to renovations.\n",
    "\n",
    "* To define a clear stakeholder and business problem that relates to the King County House Sales dataset, and to use this problem to guide the analysis and modelling process.\n",
    "\n",
    "* To build and evaluate multiple linear regression models using various combinations of the available features in the dataset, with the aim of identifying the most relevant and impactful features for predicting house sale prices.\n",
    "\n",
    "* To use appropriate statistical techniques to refine and optimize the regression models, and to clearly explain the rationale behind each technique used.\n",
    "\n",
    "* To demonstrate an iterative approach to modelling, documenting each stage of the process and providing justification for each model modification .\n",
    "\n",
    "* To provide a final documentation that includes a detailed analysis of the chosen model, including relevant metrics describing overall model performance and the coefficients of the most impactful features, and a clear explanation of how the model adds value to the stakeholder and the appropriate recommendations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Metric of Success* \n",
    "\n",
    "The final step in evaluating the quality of the model is cross-validation, which gives us an idea of how the model would perform with new data for the same variables.  one that the model will be trained on, and another that it will be tested on. By default, the function takes 75% of the data as the training subset and the other 25% as its test subset.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "\n",
    "# Pandas for reading the data and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Numpy for numbers\n",
    "import numpy as np\n",
    "\n",
    "# Seaborn and Matplotlib for Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "\n",
    "# Statsmodels and Scipy for Statistical Analysis\n",
    "from statsmodels.stats.power import TTestIndPower, TTestPower\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Warnings to remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The below code reads the CSV file 'kc_house_data.csv'  using the pandas library. The data is loaded into a pandas DataFrame object named 'df'. It then views the first few rows. \n",
    "\n",
    "* The cells that follow check for overview information on the data and then calls for descriptive statistics of the dataset.\n",
    "\n",
    "* Other important checks include checking the shape of the data, checking the columns and checking for duplicated entries as well as drops them permanently from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>6 Low Average</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21592</th>\n",
       "      <td>263000018</td>\n",
       "      <td>5/21/2014</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21593</th>\n",
       "      <td>6600060120</td>\n",
       "      <td>2/23/2015</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>2310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21594</th>\n",
       "      <td>1523300141</td>\n",
       "      <td>6/23/2014</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21595</th>\n",
       "      <td>291310100</td>\n",
       "      <td>1/16/2015</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>1523300157</td>\n",
       "      <td>10/15/2014</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21597 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id        date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0      7129300520  10/13/2014  221900.0         3       1.00         1180   \n",
       "1      6414100192   12/9/2014  538000.0         3       2.25         2570   \n",
       "2      5631500400   2/25/2015  180000.0         2       1.00          770   \n",
       "3      2487200875   12/9/2014  604000.0         4       3.00         1960   \n",
       "4      1954400510   2/18/2015  510000.0         3       2.00         1680   \n",
       "...           ...         ...       ...       ...        ...          ...   \n",
       "21592   263000018   5/21/2014  360000.0         3       2.50         1530   \n",
       "21593  6600060120   2/23/2015  400000.0         4       2.50         2310   \n",
       "21594  1523300141   6/23/2014  402101.0         2       0.75         1020   \n",
       "21595   291310100   1/16/2015  400000.0         3       2.50         1600   \n",
       "21596  1523300157  10/15/2014  325000.0         2       0.75         1020   \n",
       "\n",
       "       sqft_lot  floors waterfront  view  ...          grade sqft_above  \\\n",
       "0          5650     1.0        NaN  NONE  ...      7 Average       1180   \n",
       "1          7242     2.0         NO  NONE  ...      7 Average       2170   \n",
       "2         10000     1.0         NO  NONE  ...  6 Low Average        770   \n",
       "3          5000     1.0         NO  NONE  ...      7 Average       1050   \n",
       "4          8080     1.0         NO  NONE  ...         8 Good       1680   \n",
       "...         ...     ...        ...   ...  ...            ...        ...   \n",
       "21592      1131     3.0         NO  NONE  ...         8 Good       1530   \n",
       "21593      5813     2.0         NO  NONE  ...         8 Good       2310   \n",
       "21594      1350     2.0         NO  NONE  ...      7 Average       1020   \n",
       "21595      2388     2.0        NaN  NONE  ...         8 Good       1600   \n",
       "21596      1076     2.0         NO  NONE  ...      7 Average       1020   \n",
       "\n",
       "       sqft_basement yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0                0.0     1955           0.0    98178  47.5112 -122.257   \n",
       "1              400.0     1951        1991.0    98125  47.7210 -122.319   \n",
       "2                0.0     1933           NaN    98028  47.7379 -122.233   \n",
       "3              910.0     1965           0.0    98136  47.5208 -122.393   \n",
       "4                0.0     1987           0.0    98074  47.6168 -122.045   \n",
       "...              ...      ...           ...      ...      ...      ...   \n",
       "21592            0.0     2009           0.0    98103  47.6993 -122.346   \n",
       "21593            0.0     2014           0.0    98146  47.5107 -122.362   \n",
       "21594            0.0     2009           0.0    98144  47.5944 -122.299   \n",
       "21595            0.0     2004           0.0    98027  47.5345 -122.069   \n",
       "21596            0.0     2008           0.0    98144  47.5941 -122.299   \n",
       "\n",
       "       sqft_living15  sqft_lot15  \n",
       "0               1340        5650  \n",
       "1               1690        7639  \n",
       "2               2720        8062  \n",
       "3               1360        5000  \n",
       "4               1800        7503  \n",
       "...              ...         ...  \n",
       "21592           1530        1509  \n",
       "21593           1830        7200  \n",
       "21594           1020        2007  \n",
       "21595           1410        1287  \n",
       "21596           1020        1357  \n",
       "\n",
       "[21597 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the data\n",
    "def read_data(path):\n",
    "    \"\"\"A simple function to read our data\"\"\"\n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    return data\n",
    "\n",
    "    \n",
    "df = read_data('kc_house_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns included in the dataset are: ['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n"
     ]
    }
   ],
   "source": [
    "# Validating the columns\n",
    "def read_columns(data):\n",
    "    \"\"\"A simple function to display the columns\"\"\"\n",
    "    print(f\"Columns included in the dataset are: {list(data.columns)}\")\n",
    "    \n",
    "read_columns(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21597 non-null  int64  \n",
      " 1   date           21597 non-null  object \n",
      " 2   price          21597 non-null  float64\n",
      " 3   bedrooms       21597 non-null  int64  \n",
      " 4   bathrooms      21597 non-null  float64\n",
      " 5   sqft_living    21597 non-null  int64  \n",
      " 6   sqft_lot       21597 non-null  int64  \n",
      " 7   floors         21597 non-null  float64\n",
      " 8   waterfront     19221 non-null  object \n",
      " 9   view           21534 non-null  object \n",
      " 10  condition      21597 non-null  object \n",
      " 11  grade          21597 non-null  object \n",
      " 12  sqft_above     21597 non-null  int64  \n",
      " 13  sqft_basement  21597 non-null  object \n",
      " 14  yr_built       21597 non-null  int64  \n",
      " 15  yr_renovated   17755 non-null  float64\n",
      " 16  zipcode        21597 non-null  int64  \n",
      " 17  lat            21597 non-null  float64\n",
      " 18  long           21597 non-null  float64\n",
      " 19  sqft_living15  21597 non-null  int64  \n",
      " 20  sqft_lot15     21597 non-null  int64  \n",
      "dtypes: float64(6), int64(9), object(6)\n",
      "memory usage: 3.5+ MB\n",
      "None\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "          The shape the dataset is: (21597, 21)\n",
      "          with number of columns as 21597\n",
      "          and the number of rows as 21\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "# Getting the shape and info of the data\n",
    "def get_info_shape(data):\n",
    "    \"\"\"A simple function to get the general information of the data\"\"\"\n",
    "    \n",
    "    print(data.info())\n",
    "    print('+++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "    print('+++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "    print(f\"\"\"\n",
    "          The shape the dataset is: {data.shape}\n",
    "          with number of columns as {data.shape[0]}\n",
    "          and the number of rows as {data.shape[1]}\n",
    "          \"\"\")\n",
    "\n",
    "get_info_shape(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking and dropping duplicated Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      We have 0.0% of duplicates in our dataset\n",
      "      \n",
      "\n",
      "      We have a total of 177 duplicates out of 21597 entries\n",
      "      which corresponds to 0.81% of duplicates in the house unique identifier 'id'\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicated entry percentages\n",
    "def check_duplicates(data):\n",
    "    \"\"\"A simple function to check for duplicated entry percentages in the data\"\"\"\n",
    "    freq_dict = {}\n",
    "    for elem in data:\n",
    "        if elem in freq_dict:\n",
    "            freq_dict[elem] += 1\n",
    "        else:\n",
    "            freq_dict[elem] = 1\n",
    "    \n",
    "    num_duplicates = 0\n",
    "    for freq in freq_dict.values():\n",
    "        if freq > 1:\n",
    "            num_duplicates += 1\n",
    "    \n",
    "    percentage_duplicates = (num_duplicates / len(data)) * 100\n",
    "    \n",
    "    return percentage_duplicates\n",
    "\n",
    "print(f\"\"\"\n",
    "      We have {check_duplicates(df)}% of duplicates in our dataset\n",
    "      \"\"\")\n",
    "print(f\"\"\"\n",
    "      We have a total of {df['id'].duplicated().sum()} duplicates out of {df.shape[0]} entries\n",
    "      which corresponds to {round(check_duplicates(df['id']),2)}% of duplicates in the house unique identifier 'id'\n",
    "      \"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizations of the missing data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> #### The column \"id\" is a unique identifier for a house and thus we drop those that are duplicated and retain the first entry. Inplace= True is added to ensure the change is carried foward when the data is called again\n",
    "\n",
    "* #### This is confirmed using the ```.shape``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Permanently dropping duplicates from the subset \"id\"\n",
    "def drop_duplicates(data, subset):\n",
    "    \"\"\"A simple function to drop duplicates in a subset\"\"\"\n",
    "    print(data.drop_duplicates(subset=subset, keep='first', inplace=True))\n",
    "    \n",
    "drop_duplicates(df, \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21420 entries, 0 to 21596\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21420 non-null  int64  \n",
      " 1   date           21420 non-null  object \n",
      " 2   price          21420 non-null  float64\n",
      " 3   bedrooms       21420 non-null  int64  \n",
      " 4   bathrooms      21420 non-null  float64\n",
      " 5   sqft_living    21420 non-null  int64  \n",
      " 6   sqft_lot       21420 non-null  int64  \n",
      " 7   floors         21420 non-null  float64\n",
      " 8   waterfront     19067 non-null  object \n",
      " 9   view           21357 non-null  object \n",
      " 10  condition      21420 non-null  object \n",
      " 11  grade          21420 non-null  object \n",
      " 12  sqft_above     21420 non-null  int64  \n",
      " 13  sqft_basement  21420 non-null  object \n",
      " 14  yr_built       21420 non-null  int64  \n",
      " 15  yr_renovated   17616 non-null  float64\n",
      " 16  zipcode        21420 non-null  int64  \n",
      " 17  lat            21420 non-null  float64\n",
      " 18  long           21420 non-null  float64\n",
      " 19  sqft_living15  21420 non-null  int64  \n",
      " 20  sqft_lot15     21420 non-null  int64  \n",
      "dtypes: float64(6), int64(9), object(6)\n",
      "memory usage: 3.6+ MB\n",
      "None\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "          The shape the dataset is: (21420, 21)\n",
      "          with number of columns as 21420\n",
      "          and the number of rows as 21\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "# confirming dropped rows using the shape\n",
    "get_info_shape(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking and Dropping Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                  0\n",
      "date                0\n",
      "price               0\n",
      "bedrooms            0\n",
      "bathrooms           0\n",
      "sqft_living         0\n",
      "sqft_lot            0\n",
      "floors              0\n",
      "waterfront       2353\n",
      "view               63\n",
      "condition           0\n",
      "grade               0\n",
      "sqft_above          0\n",
      "sqft_basement       0\n",
      "yr_built            0\n",
      "yr_renovated     3804\n",
      "zipcode             0\n",
      "lat                 0\n",
      "long                0\n",
      "sqft_living15       0\n",
      "sqft_lot15          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for null values in the dataset\n",
    "def drop_null(data, subset, axis): # Subset should be a list\n",
    "    \"\"\"A simple function to find null entries and drop them\"\"\"\n",
    "    print(f\"{df.isna().sum()}\")\n",
    "    df.dropna(subset=subset, inplace=True, axis=axis)\n",
    "\n",
    "drop_null(df, ['yr_renovated', 'waterfront'], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15691 entries, 1 to 21596\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             15691 non-null  int64  \n",
      " 1   date           15691 non-null  object \n",
      " 2   price          15691 non-null  float64\n",
      " 3   bedrooms       15691 non-null  int64  \n",
      " 4   bathrooms      15691 non-null  float64\n",
      " 5   sqft_living    15691 non-null  int64  \n",
      " 6   sqft_lot       15691 non-null  int64  \n",
      " 7   floors         15691 non-null  float64\n",
      " 8   waterfront     15691 non-null  object \n",
      " 9   view           15644 non-null  object \n",
      " 10  condition      15691 non-null  object \n",
      " 11  grade          15691 non-null  object \n",
      " 12  sqft_above     15691 non-null  int64  \n",
      " 13  sqft_basement  15691 non-null  object \n",
      " 14  yr_built       15691 non-null  int64  \n",
      " 15  yr_renovated   15691 non-null  float64\n",
      " 16  zipcode        15691 non-null  int64  \n",
      " 17  lat            15691 non-null  float64\n",
      " 18  long           15691 non-null  float64\n",
      " 19  sqft_living15  15691 non-null  int64  \n",
      " 20  sqft_lot15     15691 non-null  int64  \n",
      "dtypes: float64(6), int64(9), object(6)\n",
      "memory usage: 2.6+ MB\n",
      "None\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "          The shape the dataset is: (15691, 21)\n",
      "          with number of columns as 15691\n",
      "          and the number of rows as 21\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "# Confirming the dropped columns\n",
    "get_info_shape(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### In the above cells, we dropped rows with null values in the categorical columns as it would not be wise to fill them with biased information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
